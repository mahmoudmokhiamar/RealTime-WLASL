{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TFlite inference on an example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: [{'name': 'serving_default_inputs:0', 'index': 0, 'shape': array([  1, 390], dtype=int32), 'shape_signature': array([ -1, 390], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Predicted Phrase: hello wirld\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load inference arguments\n",
    "with open(\"inference_args.json\", \"r\") as f:\n",
    "    inference_config = json.load(f)\n",
    "selected_columns = inference_config[\"selected_columns\"]\n",
    "\n",
    "# Load captured landmarks\n",
    "pq_file = \"output_landmarks.parquet\"\n",
    "df = pd.read_parquet(pq_file)\n",
    "\n",
    "# Handle missing columns\n",
    "missing_columns = [col for col in selected_columns if col not in df.columns]\n",
    "for col in missing_columns:\n",
    "    df[col] = 0.0  # Fill missing columns with zeros\n",
    "\n",
    "# Ensure columns are in the correct order\n",
    "frames = df[selected_columns].to_numpy(dtype=np.float32)\n",
    "\n",
    "# Load TFLite model\n",
    "model_path = \"model.tflite\"\n",
    "interpreter = tflite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Verify input shape\n",
    "input_details = interpreter.get_input_details()\n",
    "print(\"Input Details:\", input_details)\n",
    "\n",
    "# Check input shape\n",
    "expected_shape = input_details[0]['shape']  # [batch_size, num_features]\n",
    "if len(frames.shape) != len(expected_shape):\n",
    "    raise ValueError(f\"Dimension mismatch: Expected {len(expected_shape)} dimensions, but got {len(frames.shape)}.\")\n",
    "if frames.shape[1] != expected_shape[1]:\n",
    "    raise ValueError(f\"Shape mismatch: Model expects {expected_shape[1]} features, but got {frames.shape[1]}.\")\n",
    "\n",
    "# Allocate tensors\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], frames.shape)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Run inference\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "output = prediction_fn(inputs=frames)\n",
    "\n",
    "# Decode predictions\n",
    "with open(\"character_to_prediction_index.json\", \"r\") as f:\n",
    "    character_map = json.load(f)\n",
    "rev_character_map = {v: k for k, v in character_map.items()}\n",
    "\n",
    "# Get predicted string\n",
    "prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[\"outputs\"], axis=1)])\n",
    "print(\"Predicted Phrase:\", prediction_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
